Note the underlying supervised model used in this repo is not exactly the same as the one we reported in the ICML paper. Nonetheless, the accuracy improvement amount by semantic loss is roughly the same (~4.3%).

Accuracy report
train_semi (using semantic loss): 80.74%
train_no_unlabeled (omit unlabeled samples): 76.44%